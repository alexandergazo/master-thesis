%%% Basic information on the thesis

\def\ThesisTitle{Algorithms for Document Retrieval in Czech Language Supporting Long Inputs}
\def\ThesisTitleSk{Metody document retrieval nad českými texty vhodné pro zpracování dlouhých vstupů}

\def\ThesisAuthor{Bc. Alexander Gažo}

\def\YearSubmitted{2021}

% Name of the department or institute where the work was officially assigned
\def\Department{Department of Computer Science}
\def\DepartmentSk{Katedra počítačů}

% Is it a department (katedra), or an institute (ústav)?
\def\DeptType{Department}
\def\DeptTypeSk{Katedra}

% Thesis supervisor: name, surname, and titles
\def\Supervisor{Ing. Jan Drchal, Ph.D.}

% Supervisor's department
%\def\SupervisorsDepartment{Department of Theoretical Computer Science, FIT}
\def\SupervisorsDepartment{Artificial Intelligence Center FEE CTU}
\def\SupervisorsDepartmentSk{Centrum Umělé Inteligence FEL ČVUT}

% Study programme and specialization
\def\StudyProgramme{Open Informatics}
\def\StudyBranch{Artificial Intelligence}

% An optional dedication
\def\Dedication{%
    DEDICATION TODO
}

% Abstract (recommended length around 80-200 words; this is not a copy of your thesis assignment!)
\def\Abstract{%
    FIRST DRAFT:
    The task of document retrieval is a well-studied problem of finding the relevant subset of documents to the provided search query.
    Recent advances in the field of Natural Language Processing (NLP), namely the transformer architecture \citep{attention-is-all-you-need} and BERT model \citep{bert} provide a new approach to document retrieval.
    The document retrieval in this thesis is motivated by the Czech fact-checking task, which is an important challenge in the modern world.
    In this thesis, we apply the latest research achievements to the transformer's attention mechanism \citep{first-attention}, decreasing the space and time complexity, allowing for longer input sequences.
    We then study whether the processing of whole articles, unlike only its paragraphs, improves the performance of the retrieval models.
}
\def\AbstractSk{%
    AUTOMATICALLY TRANSLATED:
    Úloha vyhľadávania dokumentov je dobre preštudovaný problém nájdenia príslušnej podmnožiny dokumentov k poskytnutému vyhľadávaciemu dotazu.
    Nedávny pokrok v oblasti spracovania prirodzeného jazyka (NLP), konkrétne architektúra transformátora \citep{attention-is-all-you-need} a model BERT \citep{bert}, poskytujú nový prístup k vyhľadávaniu dokumentov.
    Získavanie dokumentov v tejto práci je motivované českou úlohou overovania faktov, ktorá je v modernom svete dôležitou výzvou.
    V tejto práci aplikujeme najnovšie výsledky výskumu na mechanizmus pozornosti transformátora \citep{first-attention}, znižujeme priestorovú a časovú zložitosť, čo umožňuje dlhšie vstupné sekvencie.
    Potom skúmame, či spracovanie celých článkov na rozdiel od iba jeho odsekov zlepšuje výkonnosť vyhľadávacích modelov.
}

% 3 to 5 keywords (recommended), each enclosed in curly braces
\def\Keywords{%
    {document retrieval},
    {fact-checking},
    {long-inputs},
    {Czech language},
    {NLP},
    {BERT},
    {TFIDF}
}
\def\KeywordsSk{%
    {vyhľadávanie dokumentov},
    {overovanie faktov},
    {dlhé vstupy},
    {český jazyk},
    {NLP},
    {BERT},
    {TFIDF}
}
